Namespace(EMA=0.996, aug1='t_warp', aug2='negate', backbone='Transformer', batch_size=256, cases='random', criterion='NTXent', cuda=0, dataset='uci', device='Phones', framework='simclr', lambda1=1.0, lambda2=1.0, len_sw=120, logdir='log/', lr=0.003, lr_cls=0.03, lr_mul=10.0, mmb_size=1024, model_name='try_scheduler_simclr_pretrain_uci_eps120_lr0.003_bs256_aug1t_warp_aug2negate_dim-pdim128-128_EMA0.996_criterion_NTXent_lambda1_1.0_lambda2_1.0_tempunit_tsfm', n_class=6, n_epoch=120, n_feature=9, p=128, phid=128, plt=False, scheduler=True, split_ratio=0.2, target_domain='0', temp_unit='tsfm', weight_decay=1e-06)
Namespace(EMA=0.996, aug1='t_warp', aug2='negate', backbone='Transformer', batch_size=256, cases='random', criterion='NTXent', cuda=0, dataset='uci', device='Phones', framework='simclr', lambda1=1.0, lambda2=1.0, len_sw=120, logdir='log/', lr=0.003, lr_cls=0.03, lr_mul=10.0, mmb_size=1024, model_name='try_scheduler_simclr_pretrain_uci_eps120_lr0.003_bs256_aug1t_warp_aug2negate_dim-pdim128-128_EMA0.996_criterion_NTXent_lambda1_1.0_lambda2_1.0_tempunit_tsfm', n_class=6, n_epoch=120, n_feature=6, p=128, phid=128, plt=False, scheduler=True, split_ratio=0.2, target_domain='0', temp_unit='tsfm', weight_decay=1e-06)

Epoch : 0
Train Loss : 7.0115
Namespace(EMA=0.996, aug1='t_warp', aug2='negate', backbone='Transformer', batch_size=256, cases='random', criterion='NTXent', cuda=0, dataset='uci', device='Phones', framework='simclr', lambda1=1.0, lambda2=1.0, len_sw=120, logdir='log/', lr=0.003, lr_cls=0.03, lr_mul=10.0, mmb_size=1024, model_name='try_scheduler_simclr_pretrain_uci_eps120_lr0.003_bs256_aug1t_warp_aug2negate_dim-pdim128-128_EMA0.996_criterion_NTXent_lambda1_1.0_lambda2_1.0_tempunit_tsfm', n_class=6, n_epoch=120, n_feature=6, p=128, phid=128, plt=False, scheduler=True, split_ratio=0.2, target_domain='0', temp_unit='tsfm', weight_decay=1e-06)

Epoch : 0
Train Loss : 7.0115
Val Loss : 0.0000

Epoch : 1
Train Loss : 6.2415
Val Loss : 0.0000

Epoch : 2
Train Loss : 6.2370
Val Loss : 0.0000

Epoch : 3
Train Loss : 6.2365
Val Loss : 0.0000

Epoch : 4
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 5
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 6
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 7
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 8
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 9
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 10
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 11
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 12
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 13
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 14
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 15
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 16
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 17
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 18
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 19
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 20
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 21
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 22
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 23
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 24
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 25
Train Loss : 6.2363
Val Loss : 0.0000

Epoch : 26
Train Loss : 6.2362
Val Loss : 0.0000

Epoch : 27
Train Loss : 6.2359
Val Loss : 0.0000

Epoch : 28
Train Loss : 6.2345
Val Loss : 0.0000

Epoch : 29
Train Loss : 6.2231
Val Loss : 0.0000

Epoch : 30
Train Loss : 6.2840
Val Loss : 0.0000

Epoch : 31
Train Loss : 6.2365
Val Loss : 0.0000

Epoch : 32
Train Loss : 6.2365
Val Loss : 0.0000

Epoch : 33
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 34
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 35
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 36
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 37
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 38
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 39
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 40
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 41
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 42
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 43
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 44
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 45
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 46
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 47
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 48
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 49
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 50
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 51
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 52
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 53
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 54
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 55
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 56
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 57
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 58
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 59
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 60
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 61
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 62
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 63
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 64
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 65
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 66
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 67
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 68
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 69
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 70
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 71
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 72
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 73
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 74
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 75
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 76
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 77
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 78
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 79
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 80
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 81
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 82
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 83
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 84
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 85
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 86
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 87
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 88
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 89
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 90
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 91
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 92
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 93
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 94
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 95
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 96
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 97
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 98
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 99
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 100
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 101
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 102
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 103
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 104
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 105
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 106
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 107
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 108
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 109
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 110
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 111
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 112
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 113
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 114
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 115
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 116
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 117
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 118
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 119
Train Loss : 6.2364
Val Loss : 0.0000
Test Loss     : 6.2485
Namespace(EMA=0.996, aug1='t_warp', aug2='negate', backbone='ResNet18', batch_size=256, cases='random', criterion='NTXent', cuda=0, dataset='uci', device='Phones', framework='simclr', lambda1=1.0, lambda2=1.0, len_sw=120, logdir='log/', lr=0.003, lr_cls=0.03, lr_mul=10.0, mmb_size=1024, model_name='try_scheduler_simclr_pretrain_uci_eps120_lr0.003_bs256_aug1t_warp_aug2negate_dim-pdim128-128_EMA0.996_criterion_NTXent_lambda1_1.0_lambda2_1.0_tempunit_tsfm', n_class=6, n_epoch=120, n_feature=6, p=128, phid=128, plt=False, scheduler=True, split_ratio=0.2, target_domain='0', temp_unit='tsfm', weight_decay=1e-06)

Epoch : 0
Namespace(EMA=0.996, aug1='t_warp', aug2='negate', backbone='Transformer', batch_size=256, cases='random', criterion='NTXent', cuda=0, dataset='uci', device='Phones', framework='simclr', lambda1=1.0, lambda2=1.0, len_sw=120, logdir='log/', lr=0.003, lr_cls=0.03, lr_mul=10.0, mmb_size=1024, model_name='try_scheduler_simclr_pretrain_uci_eps120_lr0.003_bs256_aug1t_warp_aug2negate_dim-pdim128-128_EMA0.996_criterion_NTXent_lambda1_1.0_lambda2_1.0_tempunit_tsfm', n_class=2, n_epoch=120, n_feature=6, p=128, phid=128, plt=False, scheduler=True, split_ratio=0.2, target_domain='0', temp_unit='tsfm', weight_decay=1e-06)

Epoch : 0
Train Loss : 6.8279
Val Loss : 0.0000

Epoch : 1
Train Loss : 6.2391
Val Loss : 0.0000

Epoch : 2
Train Loss : 6.2367
Val Loss : 0.0000

Epoch : 3
Train Loss : 6.2365
Val Loss : 0.0000

Epoch : 4
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 5
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 6
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 7
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 8
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 9
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 10
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 11
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 12
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 13
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 14
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 15
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 16
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 17
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 18
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 19
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 20
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 21
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 22
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 23
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 24
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 25
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 26
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 27
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 28
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 29
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 30
Train Loss : 6.2363
Val Loss : 0.0000

Epoch : 31
Train Loss : 6.2363
Val Loss : 0.0000

Epoch : 32
Train Loss : 6.2360
Val Loss : 0.0000

Epoch : 33
Train Loss : 6.2308
Val Loss : 0.0000

Epoch : 34
Train Loss : 6.2088
Val Loss : 0.0000

Epoch : 35
Train Loss : 6.2369
Val Loss : 0.0000

Epoch : 36
Train Loss : 6.2358
Val Loss : 0.0000

Epoch : 37
Train Loss : 6.2355
Val Loss : 0.0000

Epoch : 38
Train Loss : 6.2302
Val Loss : 0.0000

Epoch : 39
Train Loss : 6.0284
Val Loss : 0.0000

Epoch : 40
Train Loss : 6.5283
Val Loss : 0.0000

Epoch : 41
Train Loss : 6.2384
Val Loss : 0.0000

Epoch : 42
Train Loss : 6.2365
Val Loss : 0.0000

Epoch : 43
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 44
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 45
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 46
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 47
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 48
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 49
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 50
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 51
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 52
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 53
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 54
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 55
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 56
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 57
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 58
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 59
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 60
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 61
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 62
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 63
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 64
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 65
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 66
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 67
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 68
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 69
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 70
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 71
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 72
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 73
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 74
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 75
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 76
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 77
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 78
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 79
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 80
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 81
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 82
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 83
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 84
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 85
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 86
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 87
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 88
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 89
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 90
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 91
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 92
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 93
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 94
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 95
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 96
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 97
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 98
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 99
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 100
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 101
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 102
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 103
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 104
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 105
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 106
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 107
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 108
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 109
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 110
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 111
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 112
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 113
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 114
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 115
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 116
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 117
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 118
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 119
Train Loss : 6.2364
Val Loss : 0.0000
Namespace(EMA=0.996, aug1='t_warp', aug2='negate', backbone='Transformer', batch_size=256, cases='random', criterion='NTXent', cuda=0, dataset='uci', device='Phones', framework='simclr', lambda1=1.0, lambda2=1.0, len_sw=120, logdir='log/', lr=0.003, lr_cls=0.03, lr_mul=10.0, mmb_size=1024, model_name='try_scheduler_simclr_pretrain_uci_eps120_lr0.003_bs256_aug1t_warp_aug2negate_dim-pdim128-128_EMA0.996_criterion_NTXent_lambda1_1.0_lambda2_1.0_tempunit_tsfm', n_class=2, n_epoch=120, n_feature=6, p=128, phid=128, plt=False, scheduler=True, split_ratio=0.2, target_domain='0', temp_unit='tsfm', weight_decay=1e-06)

Epoch : 0
Train Loss : 7.1196
Val Loss : 0.0000

Epoch : 1
Train Loss : 6.2429
Val Loss : 0.0000

Epoch : 2
Train Loss : 6.2378
Val Loss : 0.0000

Epoch : 3
Train Loss : 6.2368
Val Loss : 0.0000

Epoch : 4
Train Loss : 6.2365
Val Loss : 0.0000

Epoch : 5
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 6
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 7
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 8
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 9
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 10
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 11
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 12
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 13
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 14
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 15
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 16
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 17
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 18
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 19
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 20
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 21
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 22
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 23
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 24
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 25
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 26
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 27
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 28
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 29
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 30
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 31
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 32
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 33
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 34
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 35
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 36
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 37
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 38
Train Loss : 6.2363
Val Loss : 0.0000

Epoch : 39
Train Loss : 6.2363
Val Loss : 0.0000

Epoch : 40
Train Loss : 6.2362
Val Loss : 0.0000

Epoch : 41
Train Loss : 6.2361
Val Loss : 0.0000

Epoch : 42
Train Loss : 6.2355
Val Loss : 0.0000

Epoch : 43
Train Loss : 6.2314
Val Loss : 0.0000

Epoch : 44
Train Loss : 6.3158
Val Loss : 0.0000

Epoch : 45
Train Loss : 6.2355
Val Loss : 0.0000

Epoch : 46
Train Loss : 6.2367
Val Loss : 0.0000

Epoch : 47
Train Loss : 6.2366
Val Loss : 0.0000

Epoch : 48
Train Loss : 6.2365
Val Loss : 0.0000

Epoch : 49
Train Loss : 6.2365
Val Loss : 0.0000

Epoch : 50
Train Loss : 6.2365
Val Loss : 0.0000

Epoch : 51
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 52
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 53
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 54
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 55
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 56
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 57
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 58
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 59
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 60
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 61
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 62
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 63
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 64
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 65
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 66
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 67
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 68
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 69
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 70
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 71
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 72
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 73
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 74
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 75
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 76
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 77
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 78
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 79
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 80
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 81
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 82
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 83
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 84
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 85
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 86
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 87
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 88
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 89
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 90
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 91
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 92
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 93
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 94
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 95
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 96
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 97
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 98
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 99
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 100
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 101
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 102
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 103
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 104
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 105
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 106
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 107
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 108
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 109
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 110
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 111
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 112
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 113
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 114
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 115
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 116
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 117
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 118
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 119
Train Loss : 6.2364
Val Loss : 0.0000
Namespace(EMA=0.996, aug1='t_warp', aug2='negate', backbone='Transformer', batch_size=256, cases='random', criterion='NTXent', cuda=0, dataset='uci', device='Phones', framework='simclr', lambda1=1.0, lambda2=1.0, len_sw=120, logdir='log/', lr=0.003, lr_cls=0.03, lr_mul=10.0, mmb_size=1024, model_name='try_scheduler_simclr_pretrain_uci_eps120_lr0.003_bs256_aug1t_warp_aug2negate_dim-pdim128-128_EMA0.996_criterion_NTXent_lambda1_1.0_lambda2_1.0_tempunit_tsfm', n_class=2, n_epoch=120, n_feature=6, p=128, phid=128, plt=False, scheduler=True, split_ratio=0.2, target_domain='0', temp_unit='tsfm', weight_decay=1e-06)

Epoch : 0
Train Loss : 6.7479
Val Loss : 0.0000

Epoch : 1
Train Loss : 6.2457
Val Loss : 0.0000

Epoch : 2
Train Loss : 6.2370
Val Loss : 0.0000

Epoch : 3
Train Loss : 6.2366
Val Loss : 0.0000

Epoch : 4
Train Loss : 6.2365
Val Loss : 0.0000

Epoch : 5
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 6
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 7
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 8
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 9
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 10
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 11
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 12
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 13
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 14
Train Loss : 6.2363
Val Loss : 0.0000

Epoch : 15
Train Loss : 6.2361
Val Loss : 0.0000

Epoch : 16
Train Loss : 6.2344
Val Loss : 0.0000

Epoch : 17
Train Loss : 6.3038
Val Loss : 0.0000

Epoch : 18
Train Loss : 6.2586
Val Loss : 0.0000

Epoch : 19
Train Loss : 6.2368
Val Loss : 0.0000

Epoch : 20
Train Loss : 6.2366
Val Loss : 0.0000

Epoch : 21
Train Loss : 6.2365
Val Loss : 0.0000

Epoch : 22
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 23
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 24
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 25
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 26
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 27
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 28
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 29
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 30
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 31
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 32
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 33
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 34
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 35
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 36
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 37
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 38
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 39
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 40
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 41
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 42
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 43
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 44
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 45
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 46
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 47
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 48
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 49
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 50
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 51
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 52
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 53
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 54
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 55
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 56
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 57
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 58
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 59
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 60
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 61
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 62
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 63
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 64
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 65
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 66
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 67
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 68
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 69
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 70
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 71
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 72
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 73
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 74
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 75
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 76
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 77
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 78
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 79
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 80
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 81
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 82
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 83
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 84
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 85
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 86
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 87
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 88
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 89
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 90
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 91
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 92
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 93
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 94
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 95
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 96
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 97
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 98
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 99
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 100
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 101
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 102
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 103
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 104
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 105
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 106
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 107
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 108
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 109
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 110
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 111
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 112
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 113
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 114
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 115
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 116
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 117
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 118
Train Loss : 6.2364
Val Loss : 0.0000

Epoch : 119
Train Loss : 6.2364
Val Loss : 0.0000
